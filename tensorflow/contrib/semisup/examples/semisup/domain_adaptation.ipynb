{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "domain_adaptation_opensource.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "0BwOs8VnGpc8uWmhNU0Q1OXNJNXM",
          "timestamp": 1477675812334
        },
        {
          "file_id": "0BwOs8VnGpc8uY2UySVNocHBXems",
          "timestamp": 1477389933424
        }
      ]
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "bh6qIVSfJn2G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "#@title imports\n",
        "from functools import partial\n",
        "import importlib\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tf.contrib.slim as slim\n",
        "from slim import preprocess\n",
        "\n",
        "import tf.app as app\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pylab as pl\n",
        "import matplotlib.patheffects as PathEffects\n",
        "\n",
        "from IPython.display import clear_output, display, Image, HTML\n",
        "\n",
        "\n",
        "from OpenCVX import cvx2 as cv2\n",
        "\n",
        "import semisup, mnist_tools, svhn_tools, synth_tools, train\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "import itertools as it\n",
        "from cStringIO import StringIO\n",
        "\n",
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NMcGn7kLK5b2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "#@title boilerplate\n",
        "\n",
        "def plot_conf_mtx(conf_mtx):\n",
        "  norm_conf = []\n",
        "  for i in conf_mtx:\n",
        "      a = 0\n",
        "      tmp_arr = []\n",
        "      a = sum(i, 0)\n",
        "      for j in i:\n",
        "          tmp_arr.append(float(j)/float(a))\n",
        "      norm_conf.append(tmp_arr)\n",
        "\n",
        "  fig = pl.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.set_aspect(1)\n",
        "  res = ax.imshow(np.array(norm_conf), cmap=pl.cm.jet, \n",
        "                  interpolation='nearest')\n",
        "\n",
        "  width, height = conf_mtx.shape\n",
        "\n",
        "  for x in xrange(width):\n",
        "      for y in xrange(height):\n",
        "          ax.annotate(str(conf_mtx[x][y]), xy=(y, x), \n",
        "                      horizontalalignment='center',\n",
        "                      verticalalignment='center', \n",
        "                      color='w', weight='bold',\n",
        "                      path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"k\")])\n",
        "\n",
        "  ax.set_xticks(range(num_labels))\n",
        "  ax.set_yticks(range(num_labels))\n",
        "\n",
        "  ax_lbls = [str(i) for i in range(num_labels)]\n",
        "  ax.set_xticklabels(ax_lbls)\n",
        "  ax.set_yticklabels(ax_lbls)\n",
        "  pl.grid()  \n",
        "\n",
        "def eval_mnist():\n",
        "  test_pred = []\n",
        "  test_lbls = []\n",
        "  runs = len(test_labels)//eval_batch_size\n",
        "  for i in range(runs):\n",
        "    print i+1, '/', runs\n",
        "    clear_output(True)\n",
        "    res = sess.run([test_predictions, t_test_labels])\n",
        "    test_pred.append(res[0])\n",
        "    test_lbls.append(res[1])\n",
        "\n",
        "  test_pred = np.array(test_pred).flatten()\n",
        "  test_lbls = np.array(test_lbls).flatten()  \n",
        "  truth_array = (test_pred == test_lbls)\n",
        "  test_err = 1.0-(truth_array).mean()\n",
        "  conf_mtx = metrics.confusion_matrix(test_lbls, test_pred)\n",
        "\n",
        "  print 'Test error: %.2f %%' % (test_err*100)\n",
        "  \n",
        "  return test_err, conf_mtx\n",
        "\n",
        "def showarray(a, fmt='jpeg'):\n",
        "    a = np.asarray(a)\n",
        "    if a.dtype in [np.float32, np.float64]:\n",
        "        a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    display(Image(data=f.getvalue()))\n",
        "\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "    \"Collect data into fixed-length chunks or blocks\"\n",
        "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\n",
        "    args = [iter(iterable)] * n\n",
        "    return it.izip_longest(fillvalue=fillvalue, *args)\n",
        "\n",
        "def tile2d(a, w=16):\n",
        "    pad = np.zeros_like(a[0])\n",
        "    return np.vstack(map(np.hstack, grouper(a, w, pad)))\n",
        "\n",
        "def plot_results(ckpt_fn): \n",
        "  removed_classes = int(ckpt_fn.split('rem')[1].split('/')[0])\n",
        "  cfg = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
        "  sess = tf.InteractiveSession(graph=graph, config=cfg)\n",
        "  tf.initialize_all_variables().run()\n",
        "  coord = tf.Coordinator()\n",
        "  threads = tf.start_queue_runners(sess=sess, coord=coord)\n",
        "\n",
        "  saver = tf.Saver()\n",
        "  saver.restore(sess, ckpt_fn)\n",
        "\n",
        "  test_pred = []\n",
        "  test_lbls = []\n",
        "  runs = len(test_labels)//eval_batch_size\n",
        "  for i in range(runs):\n",
        "    print i+1, '/', runs\n",
        "    clear_output(True)\n",
        "    res = sess.run([predictions, labels])\n",
        "    test_pred.append(res[0])\n",
        "    test_lbls.append(res[1])\n",
        "\n",
        "  coord.request_stop()\n",
        "  coord.join(threads)\n",
        "  test_pred = np.array(test_pred).flatten()\n",
        "  test_lbls = np.array(test_lbls).flatten()\n",
        "\n",
        "  truth_array = np.array([test_pred[i] == test_lbls[i] for i in range(len(test_pred)) if test_lbls[i] in range(num_labels-removed_classes)])\n",
        "  test_err = 1.0-(truth_array).mean()\n",
        "  conf_mtx = metrics.confusion_matrix(test_lbls, test_pred)\n",
        "\n",
        "  print removed_classes, 'classes removed'\n",
        "  print 'fraction of samples used for eval:', float(len(truth_array))/len(test_pred)\n",
        "  print 'Test error for not-removed classes: %.2f %%' % (test_err*100)\n",
        "\n",
        "  norm_conf = []\n",
        "  for i in conf_mtx:\n",
        "      a = 0\n",
        "      tmp_arr = []\n",
        "      a = sum(i, 0)\n",
        "      for j in i:\n",
        "          tmp_arr.append(float(j)/float(a))\n",
        "      norm_conf.append(tmp_arr)\n",
        "\n",
        "  fig = pl.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.set_aspect(1)\n",
        "  res = ax.imshow(np.array(norm_conf), cmap=pl.cm.jet, \n",
        "                  interpolation='nearest')\n",
        "\n",
        "  width, height = conf_mtx.shape\n",
        "\n",
        "  for x in xrange(width):\n",
        "      for y in xrange(height):\n",
        "          ax.annotate(str(conf_mtx[x][y]), xy=(y, x), \n",
        "                      horizontalalignment='center',\n",
        "                      verticalalignment='center', \n",
        "                      color='w', weight='bold',\n",
        "                      path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"k\")])\n",
        "  ax.vlines(x=num_labels-removed_classes-0.5 , ymin=-0.5, ymax=num_labels-0.5, color='w')\n",
        "  ax.hlines(y=num_labels-removed_classes-0.5 , xmin=-0.5, xmax=num_labels-0.5, color='w')\n",
        "  ax.set_xticks(range(num_labels))\n",
        "  ax.set_yticks(range(num_labels))\n",
        "\n",
        "  ax_lbls = [str(i) if i<num_labels-removed_classes else '(%d)' % i for i in range(num_labels)]\n",
        "  ax.set_xticklabels(ax_lbls)\n",
        "  ax.set_yticklabels(ax_lbls)\n",
        "  pl.grid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LM2QsWUr6RRM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "#@title load model trained on source domain\n",
        "\n",
        "FLAGS = train.FLAGS\n",
        "FLAGS.visit_weight = 0.5\n",
        "\n",
        "eval_batch_size = 2000\n",
        "\n",
        "# Dynamic import of the set of tools containing the network architecture etc.\n",
        "source_tools = synth_tools\n",
        "target_tools = svhn_tools\n",
        "\n",
        "num_labels = source_tools.NUM_LABELS\n",
        "image_shape = source_tools.IMAGE_SHAPE\n",
        "visit_weight = FLAGS.visit_weight\n",
        "logit_weight = FLAGS.logit_weight\n",
        "\n",
        "# Load data.\n",
        "train_images, train_labels = source_tools.get_data('train')\n",
        "train_images_unlabeled, _ = target_tools.get_data('train')\n",
        "\n",
        "test_images, test_labels = target_tools.get_data('test')\n",
        "\n",
        "\n",
        "# Sample labeled training subset.\n",
        "seed = FLAGS.sup_seed if FLAGS.sup_seed != -1 else None\n",
        "sup_by_label = semisup.sample_by_label(train_images, train_labels,\n",
        "                                       FLAGS.sup_per_class, num_labels, seed)\n",
        "\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  with tf.device(tf.ReplicaDeviceSetter(FLAGS.ps_tasks, merge_devices=True)):\n",
        "\n",
        "    # Set up inputs.\n",
        "    t_unsup_images = semisup.create_input(train_images_unlabeled, None,\n",
        "                                          FLAGS.unsup_batch_size)\n",
        "    t_sup_images, t_sup_labels = semisup.create_per_class_inputs(\n",
        "        sup_by_label, FLAGS.sup_per_batch)\n",
        "    \n",
        " \n",
        "    t_test_image, t_test_label = tf.train.slice_input_producer([test_images, test_labels])\n",
        "    t_test_images, t_test_labels = tf.train.batch(\n",
        "        [t_test_image, t_test_label], batch_size=eval_batch_size)\n",
        "    #t_test_images = tf.cast(t_test_images, tf.float32)\n",
        "    t_test_labels = tf.cast(t_test_labels, tf.int64)\n",
        "\n",
        "\n",
        "    # Resize if necessary.\n",
        "    if FLAGS.new_size > 0:\n",
        "      new_shape = [FLAGS.new_size, FLAGS.new_size, 3]\n",
        "    else:\n",
        "      new_shape = None\n",
        "      \n",
        "    # Adapt unlabeled data.\n",
        "\n",
        "\n",
        "    # Apply augmentation\n",
        "\n",
        "\n",
        "    # Create function that defines the network.\n",
        "    model_function = partial(\n",
        "        source_tools.default_model,\n",
        "        new_shape=new_shape,\n",
        "        img_shape=image_shape,\n",
        "        augmentation_function=None,\n",
        "        batch_norm_decay=FLAGS.batch_norm_decay)\n",
        "\n",
        "    # Set up semisup model.\n",
        "    model = semisup.SemisupModel(model_function, num_labels, image_shape,\n",
        "                                test_in=t_test_images)\n",
        "\n",
        "    # Compute embeddings and logits.\n",
        "    t_sup_emb = model.image_to_embedding(t_sup_images)\n",
        "    t_unsup_emb = model.image_to_embedding(t_unsup_images)\n",
        "\n",
        "    t_sup_logit = model.embedding_to_logit(t_sup_emb)\n",
        "\n",
        "    # Add losses.\n",
        "    if FLAGS.visit_weight_sigmoid:\n",
        "      visit_weight = logistic_growth(model.step, FLAGS.visit_weight,\n",
        "                                     FLAGS.max_steps)\n",
        "    else:\n",
        "      visit_weight = FLAGS.visit_weight\n",
        "    slim.summaries.add_scalar_summary(visit_weight, 'VisitLossWeight')\n",
        "\n",
        "    if FLAGS.unsup_samples != 0:\n",
        "      model.add_semisup_loss(\n",
        "          t_sup_emb, t_unsup_emb, t_sup_labels, visit_weight=visit_weight)\n",
        "    model.add_logit_loss(t_sup_logit, t_sup_labels, weight=logit_weight)\n",
        "\n",
        "    # Set up learning rate schedule if necessary.\n",
        "    if FLAGS.custom_lr_vals is not None and FLAGS.custom_lr_steps is not None:\n",
        "      boundaries = [\n",
        "          tf.convert_to_tensor(x, tf.int64) for x in FLAGS.custom_lr_steps\n",
        "      ]\n",
        "\n",
        "      t_learning_rate = tf.train.piecewise_constant(model.step, boundaries,\n",
        "                                                    FLAGS.custom_lr_vals)\n",
        "    else:\n",
        "      t_learning_rate = tf.maximum(\n",
        "          tf.train.exponential_decay(\n",
        "              FLAGS.learning_rate,\n",
        "              model.step,\n",
        "              FLAGS.decay_steps,\n",
        "              FLAGS.decay_factor,\n",
        "              staircase=True),\n",
        "          FLAGS.minimum_learning_rate)\n",
        "\n",
        "    lr_placeholder = tf.placeholder(tf.float32)\n",
        "    # Create training operation and start the actual training loop.\n",
        "    train_op = model.create_train_op(lr_placeholder)\n",
        "    \n",
        "    # Get prediction tensor from semisup model.\n",
        "    test_predictions = tf.argmax(model.test_logit, 1)\n",
        "    \n",
        "\n",
        "cfg = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
        "sess = tf.InteractiveSession(graph=graph, config=cfg)\n",
        "tf.initialize_all_variables().run()\n",
        "coord = tf.Coordinator()\n",
        "threads = tf.start_queue_runners(sess=sess, coord=coord)\n",
        "\n",
        "saver = tf.Saver()\n",
        "ckpt_fn = 'path_to_checkpoint' #@param\n",
        "saver.restore(sess, ckpt_fn)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "651mTcS7bZVV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "#@title visualize batches\n",
        "res = sess.run([t_sup_images, t_unsup_images, t_test_images])\n",
        "\n",
        "print 'sup images (source)'\n",
        "showarray(tile2d(res[0][:16]))\n",
        "\n",
        "print 'unsup images (target)'\n",
        "showarray(tile2d(res[1][:16]))\n",
        "\n",
        "print 'test images'\n",
        "showarray(tile2d(res[2][:16]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HiW0RQi16Uyc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "#@title evaluate model on target domain  \n",
        "test_err, conf_mtx = eval_mnist()  \n",
        "plot_conf_mtx(conf_mtx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-3sRDUH9jZbl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "#@title reset network to train from scratch using data from both domains\n",
        "reset = False #@param\n",
        "if reset:\n",
        "  coord.request_stop()\n",
        "  coord.join(threads)\n",
        "\n",
        "  cfg = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
        "  sess = tf.InteractiveSession(graph=graph, config=cfg)\n",
        "  tf.initialize_all_variables().run()\n",
        "  coord = tf.Coordinator()\n",
        "  threads = tf.start_queue_runners(sess=sess, coord=coord)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Yvxgrau6XzM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": null
      },
      "cell_type": "code",
      "source": [
        "loss_steps = []\n",
        "loss_vals = []\n",
        "test_steps = []\n",
        "test_errs = []\n",
        "\n",
        "step = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qyWTBoXPcoO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": null
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "  for step in xrange(step, 50000):\n",
        "    \n",
        "    lr = 1e-4 if step < 10000 else 1e-5\n",
        "    res = sess.run([train_op, model.train_loss_average], feed_dict={lr_placeholder: lr})\n",
        "\n",
        "    if step % 500 == 0:\n",
        "      test_err, conf_mtx = eval_mnist()  \n",
        "      test_steps.append(step)\n",
        "      test_errs.append(test_err)\n",
        "\n",
        "    if step % 50 == 0:\n",
        "      loss_steps.append(step)\n",
        "      loss_avg = res[1]\n",
        "      loss_vals.append(loss_avg)\n",
        "\n",
        "      print 'step', step, '| avg loss', loss_avg, '| test err', test_err*100, '%'\n",
        "      \n",
        "      best_iter = np.argmin(test_errs)\n",
        "      print 'best', test_errs[best_iter]*100, '% @ iteration', test_steps[best_iter]\n",
        "      \n",
        "      fig, ax1 = pl.subplots()\n",
        "      ax1.set_xlabel('Iteration')\n",
        "      ax1.set_ylabel('Train Loss (Avg)', color='b')\n",
        "      ax1.plot(loss_steps, loss_vals, label='avg loss', color='b')\n",
        "\n",
        "      ax2 = ax1.twinx()\n",
        "      ax2.plot(test_steps, np.array(test_errs)*100, color='r')\n",
        "      ax2.set_ylabel('Test Err (%)', color='r')\n",
        "\n",
        "      \n",
        "      plot_conf_mtx(conf_mtx)\n",
        "      pl.show()\n",
        "      clear_output(True)\n",
        "except KeyboardInterrupt:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "namZZ2t-HHB0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": null
      },
      "cell_type": "code",
      "source": [
        "cfg = tf.ConfigProto(gpu_options={'allow_growth':True})\n",
        "sess = tf.InteractiveSession(graph=graph, config=cfg)\n",
        "tf.initialize_all_variables().run()\n",
        "coord = tf.Coordinator()\n",
        "threads = tf.start_queue_runners(sess=sess, coord=coord)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m4b58VBNrp7Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": null
      },
      "cell_type": "code",
      "source": [
        "coord.request_stop()\n",
        "coord.join(threads)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GoJreHvahtMy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": null
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}